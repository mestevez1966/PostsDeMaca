--- 
category: A 
date: 2023-09-26 
image: /2023-09-26_1.png 
--- 

¿Hay una mano oscura detrás del tema de la "temperatura" de los LLM?

Yo no le encuentro sentido, la verdad. 

La "temperatura" es un hiperparámetro que controla la aleatoriedad de las respuestas generadas por el modelo. Un valor de temperatura alto (por ejemplo, 1.0 o superior) hará que el modelo genere respuestas más diversas y creativas, pero también potencialmente más incoherentes o incorrectas. Un valor de temperatura bajo (por ejemplo, 0.1) hará que el modelo genere respuestas más determinísticas, coherentes y seguras, pero también más conservadoras y menos creativas.

Más allá de la broma de turno, ¿le véis lógica a esto?

#IA #LLM #Alucinar